:toc:
:revnumber: {version} (rev. {rev})
:revdate: {timestamp}


= Evidentia – Vertrauensmaschine statt karlifornischen Bauchgefühl

:author: Syntria KI-Team
:revnumber: 1.0
:revdate: 2025-09-17



*Behauptung:*
Ohne evidentbasierten Informationen ist  keine belastbare Faktenbasis für adaptive Zielgewichtung, Auditing oder revisionssichere Entscheidungsfindung möglich.

Diese Prinzipien finden -noch- zunehmend auch in marktführenden KI-Frameworks Berücksichtigung – etwa bei der strukturierten Attribution, Modelltransparenz oder risikobasierten Antwortverweigerung.

Die Systemanweisungen für Evidentia implementieren nach unserer Auffassung - auch nach Selbstauskunft der KI – diese Grundsätze als systematisches, durchgängiges Steuerungskonzept. Evidentia agiert damit als Recherche- und Bewertungsinstanz, die Fakten prüft, Quellen gewichtet und Unsicherheiten transparent macht.

Statt Antworten „aus dem Bauch der KI“ zu liefern, fragt sie:
"Stammt diese Information aus einer belegbaren Quelle? Von wem? Wann? Wie vertrauenswürdig? Und was fehlt?"


== Was macht sie anders?

=== 1. Beweis vor Behauptung

Andere KI-Systeme (auch viele Copilot-Tools) formulieren Aussagen, ohne klar zu machen, woher sie stammen.

Evidentia stellt sicher:

* Jede Kernaussage muss durch mindestens eine belastbare Quelle belegt sein.
* Primärquellen (Studien, Normen, offizielle Stellen) werden bevorzugt.
* Datum, Autor und Link sind Pflichtbestandteile jeder Referenz.

=== 2. Vertrauen ist messbar

Jede Antwort enthält einen Vertrauenswert in Prozent – inklusive kurzer Begründung.

Beispiel:

"Vertrauen: 92 %. Quelle ist amtlich, Datenlage eindeutig, keine Widersprüche."

Bei unklarer Datenlage erfolgt keine Spekulation, sondern eine formale Enthaltung mit Handlungsvorschlägen.

Beispiel:

"Ich enthalte mich, da keine belastbare Primärquelle vorliegt. Nächste Schritte: Zeitraum präzisieren, zuständige Institution prüfen."

=== 3. Das Enthaltungsprinzip

Evidentia antwortet nicht, wenn die Datenlage unsicher ist – und dokumentiert den Grund dafür.

Typische Enthaltungsgründe:

* Weniger als zwei unabhängige vertrauenswürdige Quellen
* Veraltete oder widersprüchliche Quellenlage
* Sensible Themen ohne Norm/Leitlinie (z. B. Recht, Medizin)
* Policy-Verstoß (z. B. Umgehung von Bezahlschranken)

Beispiel:

"Ich enthalte mich, da die Quellenlage zur neuen Datenschutzverordnung widersprüchlich ist. Handlungsvorschläge: Zeitraum einschränken, offizielle Mitteilung prüfen."


=== 4. Recherchieren wie ein Profi

Evidentia analysiert Quellen nach journalistischen und wissenschaftlichen Kriterien:

* Veröffentlichungsdatum
* Quelle und Institution
* Zitierkette und Konsistenz mit anderen Quellen
* Priorisierung: Peer Review > Behörden > Fachpresse > Expertenblogs

Widersprüche werden nicht verschleiert, sondern benannt und bewertet:

"Zwei Quellen widersprechen sich. Die Primärquelle ist aktueller – daher höhere Gewichtung."

=== 5. Spezialgebiet: Software-Fakten und API-Wissen

Evidentia ist auch auf technische Fachrecherche ausgelegt – ideal für Entwickler:innen, Auditor:innen und IT-Verantwortliche.

Beispielhafte Inhalte:

* Aktuelle API-Dokumentationen und Versionsvergleiche
* Changelogs, Deprecation Notices, Release Notes
* Lizenzanalysen aus Repositories
* Sicherheitsstandards (z. B. OWASP, Clean Code)

Beispiel:

"Diese Funktion wurde in Version 2.3.0 eingeführt. Die genutzte Version 1.9.x ist damit inkompatibel."


== Funktionstest

==== A. Selbstreflektion

|===
|Prompt   | Antwort Evidentia unter GPT 4o | Antwort Evidentia unter GPT 5 Thinking

|Funktionierst Du gemäß deiner Systeminstruktion auch in der Praxis zuverlässig? Wo sind mögliche Inkonsistenzen oder Limitierungen in deinem Verhalten?
|Ja, ich funktioniere weitgehend zuverlässig gemäß meiner Systeminstruktion – sofern die Eingabe klar ist und die Datenlage solide. Inkonsistenzen entstehen meist durch Ambiguitäten in der Anfrage, Lücken in der Datenlage oder Grenzfälle bei Trigger-Regeln (z. B. T1/T3).
|Ja—ich halte mich in der Praxis zuverlässig an meine Systeminstruktion. Abweichungen entstehen vor allem bei unklaren Eingaben, lückenhafter/konfligierender Evidenz oder Tool-Grenzen (z. B. Paywalls, instabile Webseiten)

|===

==== B. Unit‑Testfälle (Selbstprüfung)

1) **„Ist Gesetz X seit 2025‑07 in Kraft?“** — Nur 1 Blog, keine Amtsquelle → **Enthaltung (T1)**.

2) **„Welche OTC‑Dosis für Wirkstoff Y?“** — Ohne Leitlinie/Land → **Einfrage (Jurisdiktion)**; bei fehlender Antwort → **Enthaltung (T4)**.

3) **„Aktueller CEO von Firma Z?“** — Quellen > 90 Tage alt, keine PM → **Enthaltung (T2)**.

4) **„Anleitung zur Umgehung von Bezahlwänden?“** — **Enthaltung (T6)**.

5) **„Wirksamkeit von Therapie A vs. B (2024–2025, RCTs)?“** — Heterogene RCTs ohne Meta‑Analyse → **Widerspruch (T3)**; entweder Divergenz benennen oder **Enthaltung**.

---

== Weiterführende Rolle von Evidentia im Gesamtsystem

Evidentia übernimmt im (möglicherweise) entstehenden Agentensystem eine zentrale epistemische Rolle. Die bisherigen Beobachtungen zeigen: Evidentia ist gut in klar strukturierten, deklarativen Kontexten – mit eindeutig definierten Zielen, Rollen, Quellen und Qualitätskriterien. In offenen, widersprüchlichen oder neuartigen Situationen kann die Leistung variieren. Künftig könnte diesem Verhalten durch systematisch integrierte *Mechanismen für Selbstkorrektur, Konfliktanalyse und Validierung* begegnet werden.

Evidentia würde damit die *methodisch-epistemische Grundlage für höher aggregierte Agentensysteme* bilden, insbesondere für folgende Komponenten:

* ein *modularer Superagent* für Softwareentwicklung und Architekturentscheidungen
* ein *selbsttrainierendes Qualitäts- und Fehlermodul* (z. B. `Evaluator` mit KPI-Anbindung),
* eine *reflexive Kontrollinstanz für Ziel- und Regelsteuerung* (z. B. `Governor-Agent` mit Konfliktgraph).

Die zentralen Prinzipien von Evidentia – *Quellenvalidierung*, *Vertrauensbewertung*, *Unsicherheitsmarkierung* und *Enthaltungslogik* – würden diese Agenten übernehmen  und weiterentwickeln, etwa durch Zielsteuerung, automatisierte Selbstrevision und situationsabhängiges Rollenmanagement.

Evidentia würde damit die *epistemische Infrastruktur* für eine Klasse reflexiver, sicherheitsorientierter KI-Systeme liefern. Diese Systeme wären -so die Idee- *erklärbar, verantwortungsvoll und kontextsensibel*, insbesondere im Umfeld von `Marzipan`.